# Unix Fundamentals

Unix is an open source family of operating systems that was developed in AT&T's Bell Lab in the early 1970's

Oringally a small terminal based OS with hierarchical file system, computer processes, and device files, the Unix family is now a giant tree of hundreds of OS's including Linux and Mac OS

The original Unix used a shell called sh, in 1989 a new shell system was created called the Bourne Again Shell aka bash, and this is the terminal all modern Unix based systems is built upon

## Linux

Linux is probably the most well known Unix based OS outside of Mac OS

Linux was created by Linus Torvalds, with support and constant updates from the open source community

Now there are many distributions of Linux, popular ones include, Ubuntu, RedHat, Arch, and more

- Ubuntu is great for first time Linux users, which is easy to understand and pick up for beginners

- Redhat is an enterprise distribution that is NOT open source, it has great resources and is used by many companies using linux to develop their code

- Arch is a highly customiziable distribution that advanced Linux users can leverage, to get the exact experience that they want

# Linux Commands

To understand Linux commands you first must understand the file structure of the Linux OS. Linux uses a tree like structure with the `root` directory mapped to the `\` character

The `home` directory is where user specific information is stored typically denoted by `~`

One last important note with the Unix file system, everything in Unix is considered a file, even directories. This is important when we get into file permissions

## Command Arguments and Flags

Commands can be modified with either arguments or flags

Arguments are given to a command after the command in the form of a string `command arg1 arg2...`

Arguments are typically variables that you command is expecting to use during execution
- Not all commands will take an argument

Flags are denoted by either a `-` followed by a letter
- Shorthand flag

Or `--` followed by the flagname
- Longhand flag

Flags are special built in arguments for the command, and they are optional for you to enable

## Unix Navigation and Directory Commands

### Most import command `man`

The manual command, it will print out the manual for a particular command, so if you are unsure of the flags or arguments, this can tell you.

Simple write `man command`

### Change Directory `cd`

The change directory command allows us to navigate to a different directory on the drive.

-   go to root directory: `cd /`
-   go to home directory: `cd` or `cd ~`
-   navigate one directory back: `cd ..`
-   navigate into the `hi` directory, which is inside the `bye` directory: `cd ./bye/hi`
-   change to the previous directory: `cd -`

### Listing Files in a directory `ls`

The list directory command allows us to see the contents of a particular directory. When given no arguments, it lists the contents of the 8 current directory.

-   `-a` flag allows you to see hidden items in the directory.
- `-l` allows you to see all the information about the files in the directory
-   list the contents of the current directory: `ls`
-   list the contents of the `hi` directory: `ls hi` or `ls ./hi`

### Make a new directory `mkdir`

The make directory command allows us to create a new directory. mkdir takes an argument representing the name of the directory you wish to create. `mkdir supercooldirectory`

### Print the current directory `pwd`

The print working directory command prints the full name of the directory you are currently working in.

## General Purpose

### Supstitute User `su` and Super User Do`sudo`

The substitute user command allows you to switch users. With no argument, this defaults to the root user, which has higher priveleges. This can be useful if you need to perform multiple commands with elevated priveleges but is generally considered to be bad practice in preference to `sudo`, for administrative logging purposes.

The `sudo` command allows you to run a particular command as the root user.

### Clear the command line with `clear`

### Print a string to the command line with `echo string`

### Redirect the output of a command to a file with `>`

### Redirect the outpuit of a command to a file without overriding the file with `>>`

### Match patterns in a file with `grep` input is a regular expression

## Linux File Commands

### Create a file `touch`

the touch command allows you to modify the timestamp of a file. This command is usually used to create empty files, as an empty file is created if touch is given a file name that does not exist.

### Print the contents of a file `cat`

### Print the first 10 lines `head` or the last 10 lines `tail` of a file

## Unix Moving and Deleting Files

### Copy the contents of a file to another file `cp`, or the contents of a directory `cp -r`

copy a `hello.txt` to `goodbye.txt`: `cp hello.txt goodbye.txt`

copy the `hello` directory to the `goodbye` directory: `cp -r hello goodbye`

### Move a file to `mv` or move a whole directory `mv -r`

the mv command allows you to rename, or move files to different directories

rename a `hello.txt` to `goodbye.txt`: `mv hello.txt goodbye.txt`

move `hello.txt` to the `goodbye` directory: `mv hello.txt ./goodbye`

rename the `hello` directory to `goodbye`: `mv hello goodbye`

### Delete a file at a specified location `rm` delete a directory `rm -r`

Never used the command `rm -rf .` this will essentially remove your entire file system

remove `hello.txt`: `rm hello.txt`

remove the `hello` directory: `rm -r hello`

### Count the words in a file `wc`

Many flags can be used with `wc` to get different outputs, including:

-   `-c, --bytes` - prints the byte count
-   `-m, --chars` - prints the character count
-   `-l, --lines` - prints the lines
-   `-w, --words` - prints the word count (default)

### Link a file to another to create a shortcut `ln`

## File Permissions in Linux

Remember that we stated that everything in linux is a file, including directories, this makes permissions easier

In Unix file system permissions are broken up into three groups: Owner, Group, and Other

Owner is the original person who created/owns the file

Group is a group of users that you can set on unix systems

Other is everyone else on the system

Each permission can is a combination of three binary numbers, each indicating what the paricular person can do

Read evaluates to the binary number 4

Write evaluates to the binary number 2

Execute evaluates to the binary number 1

You combine these three number for each of the three groups to determin the access
- This will result in a number between 0 and 7

### To set the permission level of a user/group you use `chmod` command

The simplest way to grant permissions is using the number notation which looks like this: `chmod 754`

- The 7 grants the owner all permissions
- The 5 grants the group users read and execute
- The 4 grants everyone else on the system read only

Another way is the letter notation, it uses the letters `u` for owner, `g` for group, and `o` for others, `a` for all users, in conjunction with `+`, `-`, and `=` to set the permissions for each group

`chmod a+rwx` would give full access to the all people on the sytstem

`chmod o-w` removes the write access from the other

`chmod g=u` sets the group access to the same as the owner access

# Environment Variables

Environment variables are values that are accessible in an entire working environment. In Unix, these calues are set in the shell when it is started. For example, your home directory is an environment variable called `$HOME`. If you wish to see the value of a particular environment variable you can use the echo command like so: `echo $HOME`

To set your own environment variables you use the `export` command. For example if you wanted to create an enviornment variable to store the password to your server you could do the following:

```
export SERVER_PASS=password
echo $SERVER_PASS
```

However, when you close out of the shell, and open it again, the environment variable will be gone. So to keep these variables you will have to place the export command in a script in the start directory

`~/.bashrc`

If you wanted to remove an environment variable you could so with the `unset` command

`unset SERVER_PASSWORD`

# Package Managers

In Unix based systems if you want to download/install programs or softwares you will have to use a package manager, and there are many different package managers for different distributions

RPM: Red Hat Package Manager, built for Redhat Linux, but used in other distributions, manages .rpm packages

APT: Advanced Package Tool, this is a package manager on Linux distributions, allows you to retrieve, configure, and install/uninstall software packages

YUM: Yellow Dog Updater Modifier: package management utility for OS's running RPM

DPKG: debian package, is a low level tool that manages .deb files, it was created for debian and its derivatives

# File Editors

There two popular choices when it comes to linux file editors

vi/vim is a more advanced text editor that can be configured to your exact likings, and even turned into an IDE itself with the correct configurations. A beginners guide to Vim can be found here https://www.linux.com/training-tutorials/vim-101-beginners-guide-vim/

nano is a more beginner friendly text editor that comes with most distributions of linux, a beginners guide can be found here https://www.howtogeek.com/howto/42980/the-beginners-guide-to-nano-the-linux-command-line-text-editor/

# Git Flow Overview

Git Flow is command line took that can be used with git for application that need a more complex work flow

Git flow is a workflow designed by Vincent Driessen and nvie, and its a robust framework for managing large projects by defining strict branching models design around project releases

To get started with git flow you simply run `git flow init` in your gitbash on windows, or `brew install git-flow` on mac os

The git flow sets up these strict branches for you to follow the "corrrect" workflow

The branches include:

- The main branch should hold the current production build of your app

- The development branch holds the code that will be merged into the main branch upon next release

- Features branches branch off of the development branch, and hold the more experimental code of individual features during development
    - Each one of these branches, would eventually be merged back into the development branch

- The hotfix branch is used for emergency fixes, that will need to be merged directly into the main branch upon the issue being fixed

It is best practice to NOT merge your code automatically, rather you should create pull requests on Github, or whatever remote repo service you are using.

When you create a pull request, this will essentially signify that the feature you are working is done, and ready for a code review. Then someone can review your code, and when it okayed, it will be merged

To create a pull request, go to the repo on Github > Choose the Pullrequests tab > Click on the green new pull request button

# Containers vs VM's

Containers and Virtual Machines both provide the ability to isolate processes, however each have their own pros and cons

## Virtual Machines: simulate a physical computer/server

They virtualize an entire OS

Enabled by hypervisors, a software that coordinates between multiple VM's and interfaces with the underlying infastructures

VM Pros:
- near total isolation
- provides virtualization
- ensures an application runs reliably regardless of the host

VM Cons:
- considered bulky, and expensize in the context of resources

## Container: bundle together an application with their supporting libraries and depdencies only, and allows them to run isolation

The container will share the underlying OS kernel

Making it much more light weight than a VM

Containerization is often provided by an engine running on the host, ie Docker

Container Pros:
- considered light weight, because they don't require spinning up an entire os
- they can enable layers of isolation
- provide a virtualized view of certain resources
- package an application in an isolated environment
- ensure an application runs reliably on any host

Container Cons:

- having laters of isolation can make it difficult to access excactly what you need

In general it is suggested to use Containers over VM's because of the cost of resources

## Containerization

Helps to ensure the application, or set of processes can run reliably regardless of the host.

The container, should be able to modify or interact with anything it doesnt need to and on the whole, changes in the container should not affect the outside machine

Linux Containers are the foundation of most modern container systems
- began with cgroups and name spaces
    - cgroups allow control over certain resources
    - namespaces allow for encapsulation of resources, and determining what is visible to particular processes

Containers are:
- built from an image (a template for the container)
- run on an engine (on the host OS) Docker Engine
- Are ideally stateless
    - any state that is needed for the application should be stoeed in a way that is detachable from the actual container
- Virtualized and isolated

More benefits of containers:
- Secure
- Standardized and portable
- Lightweight
- Flexible and loosely coupled
- Scalable

# Intro to Docker

Docker is an open source platform for developing, shipping, and running applications using containers

# Docker Architecture

Docker runs on a client-server architecture
- You run docker commands on the client, which interacts with the docker daemon

![docker-arch](https://docs.docker.com/engine/images/architecture.svg)

## Docker CLI

The Docker Command Line Interface, this is the client in the client-server arch
- It is used to interact with the Daemon
- Uses a rest api to send command to the docker daemon

## Docker Daemon

Is the long running process on the docker host that does all of the heavy lifting
- manages docker images
- containers
- images
- the core of the running dockerized application

## Dockerhub Container Registry

Provides a centralized place to store images, allowing you to easily share images between docker hosts
- Dockerhub is a plublic registry managed by docker, that allows you to push and pull containers

# Docker Objects

Are the building blocks that get managed by the docker daemon.

AKA the most fundamental objects of docker
- images
- containers

## Docker Images

A blueprint for the container, outlined in a dockerfile

## Docker Containers

Runnable isolation instances of a set of processes and their dependencies

- These are built from docker images, which lay out everything the proccesses need to run
- managed by the docker daemon as part of the docker engine

# Dockerfile

Define EVERYTHING needed for an image. It outlines the starting point, dependencies, and commands that make up all the proceses for an image to turn into a containers

- Use these to create our images, and they contain step by step instructions to create the image

# Dockerfile Keywords

`FROM image name`

-   Specifies the parent image from which the new image should be based

`RUN <command> / RUN ["executable", "param"]`

-   used to setup your image, the state of the image after each run command is commited forms a new layer

`ADD <src> <dest>`

-   adds files from build context or url to image

`COPY <src> <dest>`

-   adds files from build context to image, now perfered over ADD

`EXPOSE`

-   outline ports that being listened on by processes in the container

`VOLUME [/dirname]`

-   create a mount point in the image, and thus container with a particular

`WORKDIR`

-   set the working directory in the image and the eventual cointainer of commands that follow

`CMD`

-   used to execute/run processes needed inside of your container

# Building an Image

We have two ways to build an image:

1. Using the `docker build <anyflags> PATHTODOCKERFILE` command in the CLI
    - This how you can create an image with a dockerfile
2. Using the `docker commit <anyflags> CONTAINER imagename`
    - You are committing the changes from the container specified to the image specified
    - You are creating an image based off of an existing docker container

# Creating the Container

We have two ways to create a container

1. Using `docker create imagename` in the CLI
    - This creates a container in its created state, and configures it to be setup to run
2. Using `docker run <anyflags> imagename` in the CLI
    - This will pull the image either locally, or from the docker registry
    - Create and run the container automatically

# Managing Containers:

Some useful commands to manage containers include:

-   `docker container ls` displays all running containers
-   `docker ps -a` display all containers
-   `docker container kill containerID` can be used to stop a container
-   `docker container pause containerID` can pause the processes in the container
-   `docker container start containerID` can start the processes in the container
-   `docker container rm flags containerID` will remove a container
-   `docker volume rm volumename` will remove a volume

There are more commands in this cheatsheet: https://dockerlabs.collabnix.com/docker/cheatsheet/

# Docker Networking

Essentially, allowing/connecting different docker containers through a network

This allows different applications/services all running in different docker containers to communicate with one another

By default, docker provides two network drivers for you, the `bridge` and the `overlay` drivers. You can also write a network driver plugin so that you can create your own drivers but that is more advanced.

To add a container to a network you can use the command: `docker run -d --net=bridge --nameofcontainer`

# Docker Best Practices

The goals of containerization are:

-   ephemeral containers: the containers should be as easy as possible to tear down and build up requiring minimal configuration
-   lightweight containers and images

Be mindful of build context, aka what directory we are building in

Try to leverage multi-stage builds and image cache

Each container should only serve one purpose

Make commands in dockerfiles readible by separating them on different lines

Use volumes to persist data

Use secrets for sensitive data and config files for configurations that are not sensitive