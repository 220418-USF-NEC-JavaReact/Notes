# SQL vs NoSQL

## SQL

Structured Query Language

The query language used to query Relation Database Management Systems

Relation Database Management Systems have several different vendors:

- Oracle
- Postgres
- MySQL
- Microsoft SQLServer
- Microsoft Access

These are called relational databases because the tables in our databases have connections, or relationships between them

Typically, relation databases are used in OLTP systems, which means having related data is preferable in a very transactional system

Out SQL based RDBS systems are normally row based

# NoSQL Overview

Not Only SQL Databases, are non-tabular databases, which means they store data differently that our "normal" relational databases

The main types of NoSQL databases are:

- document
- key-value
- wide-column
- graph

NoSQL database are flexible, and scale easily with large amounts of data and high user loads

NoSQL databases also allows developers to store huge amounts of unstructured data, giving them a lot of flexibility

## NoSQL Database Types

Document Based: stores data in documents similar to JSON objects, each document contains pairs of fields and values

Key-Value: simpilier type of database, where each contains key and values

Wide-column: stores data in tables, rows, and dynamic columns

Graph Based: stores data in nodes and edges. Nodes typically store information about people, places, or things. And edges store information about relationships between nodes

## NoSQL Vendors

MongoDB: most widely used document based database

Cassandra: is wide column no sql database

ElasticSearch: a document based no sql database

Amazon DynamoDB: AWS key-value pair database

HBase: wide column no sql database

Neo4J: the most popular graph based database

# Querying a NoSQL Database

We will play around with MongoDB since it is one of the most popular no sql databases in use currently

1. Navigate to https://www.mongodb.com/cloud
2. Signup, or create a free account
3. Build a new database
    - Choose free since we are just playing around
    - Default settings for the free tier are fine
    - Name it if you like
    - Click create cluster
4. Setup a username and password
5. Add my Current IP Address
6. Finish and close
7. Click on the button with three dots, and choose load sample data
8. Click on Browse Collections
9. Explore the different data

# ETL Overview

Extract Transform Load

Procedure of copying data from one or more sources into a new location

Typically into a new data target, that may be in a different context than what the data was in the data source

Often this process is done in order to conform data from various sources into one collection and cohesive location

## ETL Lifecycle

The steps to extract, transform, and load data from sources into data warehouse, and then again into data marts

## Extract

Taking data from a data source
- Full extraction is taking all data from the data source
- Incremental Extraction is taking only new data from the data source
- Incremental is often implemented using a staging area to compare differences

## Transform

Converting/Modifying the extracted data to match our desired data target

- Cleaning, and making data consisten
    - Converting Null to 0
    - Converting Male to M
- Deduplication, get rid of duplicates
- Format Revision, consistent character sets, units of messure, data/time conversion
- Key Restructuring, making new key relationships across all tables

Advanced Transformations
- Deviration, applying logic to make new derived data, like averages, or other calculations
- Filtering, selecting only certain data
- Data validation, making sure the data is up to standard, could remove certain records bazed on certain conditions

## Load

Adding the data into the data target, such as an ODS, Staging Area, or Data Warehouse

- Typically a lot of data has to be loaded into a Data warehouse, optimization of performance matters

Types of loads:
- Initial load: populating all the Data warehouse tables
- Incremental Load: adding in new data periodically as needed
    - Streaming incremental load, data goes through ETL as soon as its added to the data source
    - Batch incremental load, data is loaded in chunks during set intervals
- Full refresh, remove all the data from one or more tables, and reload with fresh data